#!/usr/bin/env python3
# coding: utf-8
"""
DigVPS æ›´æ–°æ—¥å¿—æŠ“å– + å˜åŒ–æ¨é€ ServerChanï¼ˆæ–°ç‰ˆ SCTï¼‰
æ”¯æŒï¼šæ ¼å¼åŒ–ç¾è§‚è¾“å‡ºï¼Œå®¹å™¨å¯è¿è¡Œï¼Œç¼“å­˜é¿å…é‡å¤æ¨é€
"""

import os
import re
import json
import hashlib
import logging
from pathlib import Path

import requests
from bs4 import BeautifulSoup

URL = "https://digvps.com/update-log"
CACHE_FILE = "/cache/last_hash.txt"
MAX_ITEMS = 3

logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")

DATE_LINE_RE = re.compile(r"^\s*(\d{1,2}æœˆ\d{1,2}æ—¥|\d{4}[-/]\d{1,2}[-/]\d{1,2})\s*$")


# ======================
# HTTP & HTML è§£æ
# ======================

def fetch_html(url, timeout=10):
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; DigVPS-Scraper/5.0)"
    }
    r = requests.get(url, headers=headers, timeout=timeout)
    r.raise_for_status()
    r.encoding = r.apparent_encoding
    return r.text


def find_main_container(soup):
    """å°è¯•æ‰¾åˆ°ä¸»å†…å®¹åŒºåŸŸï¼Œè‹¥æ‰¾ä¸åˆ°åˆ™ fallback åˆ° bodyã€‚"""
    for sel in ("article", "main", "div.post-content", "div#content", "div.content"):
        c = soup.select_one(sel)
        if c:
            return c
    return soup.body or soup


def extract_updates(html, max_items=MAX_ITEMS):
    """æŒ‰ 'æ—¥æœŸè¡Œ â†’ å†…å®¹æ®µè½' æ¨¡å¼æå–æœ€è¿‘ N æ¡æ›´æ–°ã€‚"""
    soup = BeautifulSoup(html, "html.parser")
    main = find_main_container(soup)

    # å°†ä¸»å†…å®¹åŒºåŸŸçš„æ¯ä¸ªå­èŠ‚ç‚¹çš„æ–‡æœ¬æŠ½å–ä¸ºä¸€è¡Œ
    lines = []
    for child in main.children:
        text = (child.get_text(strip=True) if hasattr(child, "get_text") else str(child).strip())
        if text:
            text = " ".join(text.split())  # collapse ç©ºæ ¼
            lines.append((child, text))

    updates = []
    i = 0
    n = len(lines)

    while i < n and len(updates) < max_items:
        node, text = lines[i]

        # å¦‚æœæ­¤è¡Œæ˜¯æ—¥æœŸ
        if DATE_LINE_RE.match(text):
            date = DATE_LINE_RE.match(text).group(1)

            # æ”¶é›†ä¸‹é¢è¿ç»­çš„å†…å®¹ï¼ˆç›´åˆ°é‡åˆ°ä¸‹ä¸€ä¸ªæ—¥æœŸï¼‰
            content_parts = []
            j = i + 1
            while j < n:
                nxt_text = lines[j][1]
                if DATE_LINE_RE.match(nxt_text):
                    break
                content_parts.append(nxt_text)
                j += 1

            if content_parts:
                full = date + "\n" + "\n".join(content_parts)
            else:
                full = date

            updates.append(full)
            i = j
        else:
            i += 1

    return updates


# ======================
# æ¨é€æ ¼å¼ç¾åŒ–
# ======================

def format_updates(updates):
    """
    å°† ["12æœˆ11æ—¥\nxxx", "12æœˆ10æ—¥\nxxx"] æ ¼å¼åŒ–ä¸ºæ›´ç¾è§‚çš„ markdownã€‚
    """
    formatted = []

    for item in updates:
        lines = item.split("\n")
        date = lines[0]
        content = " ".join(lines[1:]).strip()

        block = (
            f"### ğŸ—“ {date}\n"
            f"{content}\n"
        )
        formatted.append(block)

    return "\n".join(formatted)


# ======================
# ç¼“å­˜åˆ¤æ–­ï¼ˆé¿å…é‡å¤æ¨é€ï¼‰
# ======================

def calc_hash(items):
    return hashlib.sha256(json.dumps(items, ensure_ascii=False).encode()).hexdigest()


def load_last_hash():
    p = Path(CACHE_FILE)
    if p.exists():
        return p.read_text(encoding="utf-8").strip()
    return ""


def save_last_hash(h):
    p = Path(CACHE_FILE)
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(h, encoding="utf-8")


# ======================
# ServerChan æ¨é€ï¼ˆæ–°ç‰ˆ SCTï¼‰
# ======================

def push_serverchan(title, desp):
    sckey = os.getenv("SERVERCHAN_SCKEY")
    if not sckey:
        logging.error("æœªè®¾ç½® SERVERCHAN_SCKEY")
        return False

    api = f"https://sctapi.ftqq.com/{sckey}.send"

    try:
        r = requests.post(api, data={"title": title, "desp": desp}, timeout=10)
        try:
            j = r.json()
            logging.info("ServerChan è¿”å›ï¼š%s", j)
            return j.get("code", 0) == 0 or r.status_code == 200
        except Exception:
            return r.status_code == 200
    except Exception as e:
        logging.error("æ¨é€å¤±è´¥ï¼š%s", e)
        return False


# ======================
# ä¸»å‡½æ•°
# ======================

def main():
    try:
        html = fetch_html(URL)
    except Exception as e:
        logging.error("æŠ“å–å¤±è´¥ï¼š%s", e)
        return

    updates = extract_updates(html)
    if not updates:
        logging.error("æœªè§£æåˆ°ä»»ä½•æ›´æ–°å†…å®¹ï¼Œè¯·æ£€æŸ¥é¡µé¢ç»“æ„å˜åŒ–")
        return

    logging.info("æˆåŠŸè§£æåˆ° %d æ¡æ›´æ–°", len(updates))

    new_hash = calc_hash(updates)
    old_hash = load_last_hash()

    if new_hash == old_hash:
        logging.info("å†…å®¹æœªå˜åŒ–ï¼Œä¸æ¨é€")
        return

    body = format_updates(updates)
    body += f"\n\nğŸ‘‰ æ¥æºï¼š{URL}"

    ok = push_serverchan("DigVPS æ›´æ–°æ—¥å¿—ï¼ˆæœ‰æ›´æ–°ï¼‰", body)

    if ok:
        save_last_hash(new_hash)
        logging.info("æ¨é€æˆåŠŸå¹¶æ›´æ–°ç¼“å­˜")
    else:
        logging.error("æ¨é€å¤±è´¥")


if __name__ == "__main__":
    main()

